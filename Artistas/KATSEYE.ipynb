{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec233d8-99f1-483f-ac87-45e6f3506c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by KATSEYE...\n",
      "\n",
      "Song 1: \"Gnarly\"\n",
      "Song 2: \"Gabriela\"\n",
      "Song 3: \"Touch\"\n",
      "Song 4: \"Gameboy\"\n",
      "\n",
      "Reached user-specified song limit (4).\n",
      "Done. Found 4 songs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import lyricsgenius\n",
    "import csv\n",
    "\n",
    "# Chamada de Requisição\n",
    "api_key = \"peEF0f6fbemhrR03PJBjFDGjdaQlkiAr4t1VUu7m-3LcaR7AY9hWTbBPcyEwZo6R\"\n",
    "genius = lyricsgenius.Genius(api_key)\n",
    "\n",
    "# Busca do artista na API\n",
    "artist = genius.search_artist(\"KATSEYE\", max_songs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb61455-3339-4ea1-a025-7ac215286bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Lyrics_KATSEYE.json.\n"
     ]
    }
   ],
   "source": [
    "# Importando para um arquivo json\n",
    "artist.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3997f19c-be7a-465b-a6cf-598d32879aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alternate_names', 'api_path', 'description', 'facebook_name', 'header_image_url', 'id', 'image_url', 'instagram_name', 'is_meme_verified', 'is_verified', 'name', 'translation_artist', 'twitter_name', 'url', 'current_user_metadata', 'followers_count', 'description_annotation', 'user', 'songs'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acessando as chaves principais dos dados contidos no arquivo JSON\n",
    "data = json.load(open(\"Lyrics_KATSEYE.json\", \"r\"))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0106275b-0d0b-4cda-aab3-5ff873982b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['annotation_count', 'api_path', 'artist_names', 'full_title',\n",
       "       'header_image_thumbnail_url', 'header_image_url', 'id',\n",
       "       'lyrics_owner_id', 'lyrics_state', 'path', 'primary_artist_names',\n",
       "       'pyongs_count', 'relationships_index_url', 'release_date_components',\n",
       "       'release_date_for_display',\n",
       "       'release_date_with_abbreviated_month_for_display',\n",
       "       'song_art_image_thumbnail_url', 'song_art_image_url', 'stats', 'title',\n",
       "       'title_with_featured', 'url', 'featured_artists', 'primary_artist',\n",
       "       'primary_artists', 'apple_music_id', 'apple_music_player_url',\n",
       "       'description', 'embed_content', 'language', 'recording_location',\n",
       "       'release_date', 'current_user_metadata', 'song_art_primary_color',\n",
       "       'song_art_secondary_color', 'song_art_text_color', 'album',\n",
       "       'custom_performances', 'description_annotation',\n",
       "       'lyrics_marked_complete_by', 'lyrics_marked_staff_approved_by', 'media',\n",
       "       'producer_artists', 'song_relationships', 'translation_songs',\n",
       "       'verified_annotations_by', 'verified_contributors',\n",
       "       'verified_lyrics_by', 'writer_artists', 'artist', 'lyrics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando dados em um dataframe e examinando os dados dentro de 'songs'\n",
    "df = pd.DataFrame(data['songs'])\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53fe2648-5d05-4432-a0c7-9e2b1a425e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>release_date</th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gnarly</td>\n",
       "      <td>163 ContributorsTranslationsEspañolItalianoУкр...</td>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gabriela</td>\n",
       "      <td>70 ContributorsTranslationsEnglishPortuguêsEsp...</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Touch</td>\n",
       "      <td>34 ContributorsTranslationsNederlandsDeutschČe...</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gameboy</td>\n",
       "      <td>41 ContributorsTranslationsPortuguêsEspañolTür...</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title                                             lyrics release_date  \\\n",
       "0    Gnarly  163 ContributorsTranslationsEspañolItalianoУкр...   2025-04-30   \n",
       "1  Gabriela  70 ContributorsTranslationsEnglishPortuguêsEsp...   2025-06-20   \n",
       "2     Touch  34 ContributorsTranslationsNederlandsDeutschČe...   2024-07-26   \n",
       "3   Gameboy  41 ContributorsTranslationsPortuguêsEspañolTür...   2025-06-27   \n",
       "\n",
       "   release_year  \n",
       "0          2025  \n",
       "1          2025  \n",
       "2          2024  \n",
       "3          2025  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando os dados úteis em um novo dataframe\n",
    "df_oficial = df[['title', 'lyrics', 'release_date']].copy()\n",
    "\n",
    "# Reseta o índice, se necessário\n",
    "df_oficial.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convertendo a coluna 'release_date' para o formato de data\n",
    "df_oficial['release_date'] = pd.to_datetime(df_oficial['release_date'], errors='coerce')\n",
    "\n",
    "# Extraindo apenas o ano da coluna 'release_date' para armazenar na 'release_year'\n",
    "df_oficial['release_year'] = df_oficial['release_date'].dt.year\n",
    "\n",
    "# Exibindo o dataframe resultante\n",
    "df_oficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb05c4a-f287-46ec-9711-6c830c0da92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Define uma função para remover stopwords de um texto\n",
    "def remove_stopwords(text):\n",
    "    # Separa o texto em uma lista de palavras\n",
    "    text = text.split(' ')\n",
    "    # Filtra a lista, mantendo apenas as palavras que não estão na lista de stopwords em inglês\n",
    "    text = [x for x in text if x not in stopwords.words('english')]\n",
    "    # Junta a lista de palavras filtradas em uma única string e a retorna\n",
    "    return ' '.join(text)\n",
    "\n",
    "# Aplica a função de remoção de stopwords em cada linha da coluna 'lyrics' do dataframe\n",
    "df_oficial.loc[:, 'lyrics'] = df_oficial.loc[:, 'lyrics'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# Define uma função para remover pontuação do texto\n",
    "def remove_ponctuation(text):\n",
    "    # Usa uma expressão regular para manter apenas letras (maiúsculas e minúsculas) e junta as palavras em uma string\n",
    "    return \" \".join(re.findall(\"[a-zA-Z]+\", text))\n",
    "\n",
    "# Aplica a função de remoção de pontuação em cada linha da coluna 'lyrics' do dataframe\n",
    "df_oficial.loc[:, 'lyrics'] = df_oficial.loc[:, 'lyrics'].apply(lambda x: remove_ponctuation(x))\n",
    "\n",
    "# Define uma função para remover palavras com menos de 3 caracteres do texto\n",
    "def remove_words_with_less_3(text):\n",
    "    # Separa o texto em uma lista de palavras\n",
    "    text = text.split(' ')\n",
    "    # Filtra a lista, mantendo apenas as palavras com mais de 3 caracteres\n",
    "    text = [x for x in text if len(x) > 3]\n",
    "    # Junta a lista de palavras filtradas em uma única string e a retorna\n",
    "    return ' '.join(text)\n",
    "\n",
    "# Aplica a função de remoção de palavras curtas em cada linha da coluna 'lyrics' do dataframe\n",
    "df_oficial.loc[:, 'lyrics'] = df_oficial.loc[:, 'lyrics'].apply(lambda x: remove_words_with_less_3(x))\n",
    "\n",
    "# Converte todo o texto em letras minúsculas em cada linha da coluna 'lyrics' do dataframe\n",
    "df_oficial.loc[:, 'lyrics'] = df_oficial.loc[:, 'lyrics'].apply(lambda x: x.lower())\n",
    "\n",
    "# Cria uma nova coluna 'Word Count' no dataframe que conta o número de palavras em cada linha da coluna 'lyrics'\n",
    "df_oficial['Word Count'] = df_oficial['lyrics'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "# Função para remover as palavras indesejadas\n",
    "def remove_unwanted_words(text):\n",
    "    words_to_remove = [\"embed\", \"intro\", \"verse\", \"chorus\", \"outro\", \"instrumental\"]\n",
    "    pattern = r'\\b(?:' + '|'.join(words_to_remove) + r')\\b'\n",
    "    return re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "\n",
    "# Aplicar a função na coluna de letras\n",
    "df_oficial[\"lyrics\"] = df_oficial[\"lyrics\"].apply(remove_unwanted_words)\n",
    "\n",
    "# Salvar o CSV atualizado\n",
    "df_oficial.to_csv(\"KATSEYE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "823675a2-1bd3-4095-9f1b-e1d6bd39ffd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'lyrics' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKATSEYE.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Salvando no banco de dados\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_oficial\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics\u001b[39m\u001b[38;5;124m'\u001b[39m, conn, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Verificando se os dados estão presentes no banco de dados\u001b[39;00m\n\u001b[0;32m     10\u001b[0m c \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m   3088\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3089\u001b[0m     name,\n\u001b[0;32m   3090\u001b[0m     con,\n\u001b[0;32m   3091\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   3092\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m   3093\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3094\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3095\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3096\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3097\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   3098\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    843\u001b[0m         frame,\n\u001b[0;32m    844\u001b[0m         name,\n\u001b[0;32m    845\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    846\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    847\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    848\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    849\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    850\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    851\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    852\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    854\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2850\u001b[0m, in \u001b[0;36mSQLiteDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2839\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) not a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2841\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLiteTable(\n\u001b[0;32m   2842\u001b[0m     name,\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2848\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2849\u001b[0m )\n\u001b[1;32m-> 2850\u001b[0m table\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m   2851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize, method)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:986\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 986\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpd_sql\u001b[38;5;241m.\u001b[39mdrop_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "\u001b[1;31mValueError\u001b[0m: Table 'lyrics' already exists."
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Criando um banco de dados de teste\n",
    "conn = sqlite3.connect('KATSEYE.db')\n",
    "\n",
    "# Salvando no banco de dados\n",
    "df_oficial.to_sql('lyrics', conn, index=False)\n",
    "\n",
    "# Verificando se os dados estão presentes no banco de dados\n",
    "c = conn.cursor()\n",
    "c.execute('''\n",
    "SELECT * FROM LYRICS\n",
    "          ''')\n",
    "# Visualização do Banco de Dados gerado\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1634994d-f4e1-4024-aeaa-3de1a9b6de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Ryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Ryan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando bibliotecas de manipulação e análise de dados\n",
    "import pandas as pd  # Usado para manipulação de tabelas e dataframes\n",
    "import numpy as np   # Usado para operações matemáticas e arrays numéricos\n",
    "\n",
    "# Biblioteca de NLP (Processamento de Linguagem Natural)\n",
    "from nltk.tokenize import word_tokenize  # Quebra textos em palavras (tokens)\n",
    "\n",
    "# Baixando recursos da biblioteca NLTK\n",
    "import nltk\n",
    "nltk.download('punkt_tab')  # Tokenizador de pontuação/tabulação\n",
    "nltk.download('vader_lexicon')  # Léxico para análise de sentimentos com VADER (análise de sentimentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73e72b05-4a0d-44e3-84a9-46cc8e1cad38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>release_year</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gnarly</td>\n",
       "      <td>contributorstranslationsespa olitaliano fran k...</td>\n",
       "      <td>2025</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gabriela</td>\n",
       "      <td>contributorstranslationsenglishportugu sespa o...</td>\n",
       "      <td>2025</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Touch</td>\n",
       "      <td>contributorstranslationsnederlandsdeutsch esky...</td>\n",
       "      <td>2024</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gameboy</td>\n",
       "      <td>contributorstranslationsportugu sespa eskyfran...</td>\n",
       "      <td>2025</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title                                             lyrics  release_year  \\\n",
       "0    Gnarly  contributorstranslationsespa olitaliano fran k...          2025   \n",
       "1  Gabriela  contributorstranslationsenglishportugu sespa o...          2025   \n",
       "2     Touch  contributorstranslationsnederlandsdeutsch esky...          2024   \n",
       "3   Gameboy  contributorstranslationsportugu sespa eskyfran...          2025   \n",
       "\n",
       "   Word Count  \n",
       "0         213  \n",
       "1         198  \n",
       "2         213  \n",
       "3         190  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura do Arquivo\n",
    "df_oficial=pd.read_csv(\"KATSEYE.csv\")\n",
    "\n",
    "# Remove a coluna 'release_date'\n",
    "df_oficial = df_oficial.drop(columns=['release_date'])\n",
    "\n",
    "# Visualização do Dataframe\n",
    "df_oficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb10bb-45c1-4718-a0c7-4bdf7896f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de palavras indesejadas presentes na discografia e não identificadas na etapa de tokenização\n",
    "indesejadas = ['ally','brooke','na','yeah']\n",
    "\n",
    "# Remove as palavras indesejadas, e salva de volta como um texto longo\n",
    "df['lyrics'] = df['lyrics'].apply(lambda x: ' '.join([palavra for palavra in x.split() if palavra not in (indesejadas)]))\n",
    "\n",
    "# Une o dataframe em uma string longa/TextBlob\n",
    "text = \" \".join(twt for twt in df['lyrics'])\n",
    "palavras = word_tokenize(text)\n",
    "\n",
    "print(\"Existem {} palavras no dataset de letra.\".format(len(palavras)))\n",
    "print(\"Existem {} palavras únicas no dataset de letras.\".format(len(set(palavras))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
